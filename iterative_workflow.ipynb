{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f88a46a9",
   "metadata": {},
   "source": [
    "Tagline Generator with Feedback\n",
    "    Input: Company name + product. \n",
    "    Generator creates a tagline. \n",
    "    Checker tests if it is catchy. \n",
    "    If not catchy → refine again.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c45c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph , START , END\n",
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72918009",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model='gpt-5-nano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d007eea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujal\\AppData\\Local\\Temp\\ipykernel_25044\\3817203380.py:24: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  tagline = llm.predict(prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final tagline: \"Shaping Tomorrow, Today!\"\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class WorkflowState(dict):\n",
    "    tagline: str\n",
    "    feedback: str\n",
    "    approved: bool\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "def generate_tagline(state: WorkflowState):\n",
    "    company = state.get(\"company\")\n",
    "    product = state.get(\"product\")\n",
    "    feedback = state.get(\"feedback\", \"\")\n",
    "    prompt = f\"\"\"\n",
    "    Company: {company}\n",
    "    Product: {product}\n",
    "    {f\"Previous feedback: {feedback}\" if feedback else \"\"}\n",
    "    Generate a short, catchy tagline.\n",
    "    \"\"\"\n",
    "    tagline = llm.predict(prompt)\n",
    "    state[\"tagline\"] = tagline.strip()\n",
    "    return state\n",
    "\n",
    "def check_tagline(state: WorkflowState):\n",
    "    tagline = state[\"tagline\"]\n",
    "    check_prompt = f\"\"\"\n",
    "    Tagline: \"{tagline}\"\n",
    "    Is this tagline short, memorable, and exciting? \n",
    "    Answer only with 'yes' or 'no' and give 1 short feedback sentence if 'no'.\n",
    "    \"\"\"\n",
    "    result = llm.predict(check_prompt).lower()\n",
    "    if \"yes\" in result:\n",
    "        state[\"approved\"] = True\n",
    "    else:\n",
    "        state[\"approved\"] = False\n",
    "        state[\"feedback\"] = result\n",
    "    return state\n",
    "\n",
    "workflow = StateGraph(WorkflowState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"generate\", generate_tagline)\n",
    "workflow.add_node(\"check\", check_tagline)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(\"generate\", \"check\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"check\",\n",
    "    lambda s: END if s.get(\"approved\") else \"generate\"\n",
    ")\n",
    "\n",
    "workflow.set_entry_point(\"generate\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    initial_state = WorkflowState(company=\"EcoLife\", product=\"reusable water bottles\")\n",
    "    app = workflow.compile()\n",
    "    final_state = app.invoke(initial_state)\n",
    "    print(f\"✅ Final tagline: {final_state['tagline']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b367de87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b060881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efafe882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
